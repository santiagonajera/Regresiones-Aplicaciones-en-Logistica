{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBAaiCEG9pqFKZCfCiY7Oq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagonajera/Regresiones-Aplicaciones-en-Logistica/blob/main/RegresionesCodigo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV5wU8bIHilZ",
        "outputId": "3835e54b-7b74-43c2-ba23-f181eb8c9a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Cuadrático Medio (MSE): 25.98\n",
            "Raíz del Error Cuadrático Medio (RMSE): 5.10\n",
            "Coeficiente de Determinación R²: 0.87\n",
            "\n",
            "Coeficientes del modelo:\n",
            "                  Feature  Coefficient\n",
            "3              Dia_Semana     2.978725\n",
            "6             Clima_Nieve     1.075449\n",
            "0            Distancia_km     0.402274\n",
            "1      Cantidad_Productos     0.199699\n",
            "2             Hora_Pedido     0.143415\n",
            "7           Clima_Soleado    -1.074598\n",
            "9        Trafico_Moderado    -1.075760\n",
            "8            Trafico_Leve    -1.472537\n",
            "4  Tipo_Transporte_Camion    -1.497803\n",
            "5    Tipo_Transporte_Moto    -3.101193\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagonajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar modelo de regresión lineal múltiple\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")\n",
        "print(f\"Raíz del Error Cuadrático Medio (RMSE): {rmse:.2f}\")\n",
        "print(f\"Coeficiente de Determinación R²: {r2:.2f}\")\n",
        "\n",
        "# Mostrar coeficientes del modelo\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': model.coef_\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nCoeficientes del modelo:\")\n",
        "print(coefficients)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (importante para SVR)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Escalar el target también\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Entrenar modelo SVR\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)  # kernel='rbf' es común para problemas no lineales\n",
        "svr_model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Realizar predicciones\n",
        "y_pred_scaled = svr_model.predict(X_test_scaled)\n",
        "\n",
        "# Desescalar las predicciones para interpretarlas en la escala original\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
        "y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Evaluar el modelo\n",
        "mse = mean_squared_error(y_test_original, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_original, y_pred)\n",
        "\n",
        "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")\n",
        "print(f\"Raíz del Error Cuadrático Medio (RMSE): {rmse:.2f}\")\n",
        "print(f\"Coeficiente de Determinación R²: {r2:.2f}\")\n",
        "\n",
        "# Mostrar parámetros del modelo\n",
        "print(\"\\nParámetros del modelo SVR:\")\n",
        "print(f\"Kernel: {svr_model.kernel}\")\n",
        "print(f\"Valor de C: {svr_model.C}\")\n",
        "print(f\"Valor de epsilon: {svr_model.epsilon}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYquyerbLzQA",
        "outputId": "43c59fff-c628-44d8-e35a-ad5cb15a55ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Cuadrático Medio (MSE): 26.88\n",
            "Raíz del Error Cuadrático Medio (RMSE): 5.18\n",
            "Coeficiente de Determinación R²: 0.86\n",
            "\n",
            "Parámetros del modelo SVR:\n",
            "Kernel: rbf\n",
            "Valor de C: 1.0\n",
            "Valor de epsilon: 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (importante para SVR)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Escalar el target también\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Entrenar modelo SVR\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)  # kernel='rbf' es común para problemas no lineales\n",
        "svr_model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Realizar predicciones\n",
        "y_pred_scaled = svr_model.predict(X_test_scaled)\n",
        "\n",
        "# Desescalar las predicciones para interpretarlas en la escala original\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
        "y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Evaluar el modelo\n",
        "mse = mean_squared_error(y_test_original, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_original, y_pred)\n",
        "\n",
        "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")\n",
        "print(f\"Raíz del Error Cuadrático Medio (RMSE): {rmse:.2f}\")\n",
        "print(f\"Coeficiente de Determinación R²: {r2:.2f}\")\n",
        "\n",
        "# Interpretación de los resultados\n",
        "print(\"\\nInterpretación de los resultados:\")\n",
        "print(\"El modelo SVR no proporciona coeficientes explícitos como en la regresión lineal.\")\n",
        "print(\"Sin embargo, puedes analizar la importancia relativa de las variables usando técnicas adicionales.\")\n",
        "\n",
        "# Importancia relativa de las variables (aproximación)\n",
        "# Calculamos la sensibilidad de las predicciones al cambiar cada variable\n",
        "feature_importance = []\n",
        "for i in range(X_train_scaled.shape[1]):\n",
        "    X_temp = X_train_scaled.copy()\n",
        "    X_temp[:, i] += 0.1  # Pequeño cambio en la variable i\n",
        "    y_pred_temp = svr_model.predict(X_temp)\n",
        "    importance = np.mean(np.abs(y_pred_temp - y_train_scaled))\n",
        "    feature_importance.append(importance)\n",
        "\n",
        "# Crear un DataFrame con la importancia relativa\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': feature_importance\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nImportancia relativa de las variables:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5Aq3wVMMSpN",
        "outputId": "d8035a93-9f82-404d-b089-e84905a2d0f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Cuadrático Medio (MSE): 26.88\n",
            "Raíz del Error Cuadrático Medio (RMSE): 5.18\n",
            "Coeficiente de Determinación R²: 0.86\n",
            "\n",
            "Interpretación de los resultados:\n",
            "El modelo SVR no proporciona coeficientes explícitos como en la regresión lineal.\n",
            "Sin embargo, puedes analizar la importancia relativa de las variables usando técnicas adicionales.\n",
            "\n",
            "Importancia relativa de las variables:\n",
            "                  Feature  Importance\n",
            "1      Cantidad_Productos    0.283721\n",
            "0            Distancia_km    0.278260\n",
            "3              Dia_Semana    0.276785\n",
            "4  Tipo_Transporte_Camion    0.276769\n",
            "5    Tipo_Transporte_Moto    0.276707\n",
            "8            Trafico_Leve    0.276670\n",
            "9        Trafico_Moderado    0.276651\n",
            "7           Clima_Soleado    0.276641\n",
            "6             Clima_Nieve    0.276513\n",
            "2             Hora_Pedido    0.276489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (necesario para SVR)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Modelo 1: Regresión Lineal Múltiple\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)  # No necesita escalamiento\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "\n",
        "# Evaluar modelo de regresión lineal\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "rmse_linear = np.sqrt(mse_linear)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "# Modelo 2: Support Vector Regression (SVR)\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "svr_model.fit(X_train_scaled, y_train_scaled)\n",
        "y_pred_svr_scaled = svr_model.predict(X_test_scaled)\n",
        "y_pred_svr = scaler_y.inverse_transform(y_pred_svr_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Evaluar modelo SVR\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "# Comparar los modelos\n",
        "print(\"Comparación de modelos:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Regresión Lineal - MSE: {mse_linear:.2f}, RMSE: {rmse_linear:.2f}, R²: {r2_linear:.2f}\")\n",
        "print(f\"SVR - MSE: {mse_svr:.2f}, RMSE: {rmse_svr:.2f}, R²: {r2_svr:.2f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Determinar el mejor modelo\n",
        "if mse_linear < mse_svr and r2_linear > r2_svr:\n",
        "    print(\"El mejor modelo es: Regresión Lineal\")\n",
        "elif mse_svr < mse_linear and r2_svr > r2_linear:\n",
        "    print(\"El mejor modelo es: SVR\")\n",
        "else:\n",
        "    print(\"Ambos modelos tienen un rendimiento similar. Considera otros factores como interpretabilidad o complejidad.\")\n",
        "\n",
        "# Interpretación adicional\n",
        "print(\"\\nInterpretación:\")\n",
        "print(\"- La Regresión Lineal es más interpretable porque proporciona coeficientes explícitos.\")\n",
        "print(\"- SVR puede capturar relaciones no lineales, pero es menos interpretable y más costoso computacionalmente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB2VlnhkP_gb",
        "outputId": "683b230c-bace-4279-bdd2-dc5858f33476"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de modelos:\n",
            "--------------------------------------------------\n",
            "Regresión Lineal - MSE: 25.98, RMSE: 5.10, R²: 0.87\n",
            "SVR - MSE: 26.88, RMSE: 5.18, R²: 0.86\n",
            "--------------------------------------------------\n",
            "El mejor modelo es: Regresión Lineal\n",
            "\n",
            "Interpretación:\n",
            "- La Regresión Lineal es más interpretable porque proporciona coeficientes explícitos.\n",
            "- SVR puede capturar relaciones no lineales, pero es menos interpretable y más costoso computacionalmente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica2.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (necesario para SVR)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Modelo 1: Regresión Lineal Múltiple\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)  # No necesita escalamiento\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "\n",
        "# Evaluar modelo de regresión lineal\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "rmse_linear = np.sqrt(mse_linear)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "# Modelo 2: Support Vector Regression (SVR)\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "svr_model.fit(X_train_scaled, y_train_scaled)\n",
        "y_pred_svr_scaled = svr_model.predict(X_test_scaled)\n",
        "y_pred_svr = scaler_y.inverse_transform(y_pred_svr_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Evaluar modelo SVR\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "# Comparar los modelos\n",
        "print(\"Comparación de modelos:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Regresión Lineal - MSE: {mse_linear:.2f}, RMSE: {rmse_linear:.2f}, R²: {r2_linear:.2f}\")\n",
        "print(f\"SVR - MSE: {mse_svr:.2f}, RMSE: {rmse_svr:.2f}, R²: {r2_svr:.2f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Determinar el mejor modelo\n",
        "if mse_linear < mse_svr and r2_linear > r2_svr:\n",
        "    print(\"El mejor modelo es: Regresión Lineal\")\n",
        "elif mse_svr < mse_linear and r2_svr > r2_linear:\n",
        "    print(\"El mejor modelo es: SVR\")\n",
        "else:\n",
        "    print(\"Ambos modelos tienen un rendimiento similar. Considera otros factores como interpretabilidad o complejidad.\")\n",
        "\n",
        "# Interpretación adicional\n",
        "print(\"\\nInterpretación:\")\n",
        "print(\"- La Regresión Lineal es más interpretable porque proporciona coeficientes explícitos.\")\n",
        "print(\"- SVR puede capturar relaciones no lineales, pero es menos interpretable y más costoso computacionalmente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbD3th9BRJFD",
        "outputId": "4253a8fa-db1d-4f4a-c922-f683b4dd1ce6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de modelos:\n",
            "--------------------------------------------------\n",
            "Regresión Lineal - MSE: 27.93, RMSE: 5.28, R²: 0.86\n",
            "SVR - MSE: 28.84, RMSE: 5.37, R²: 0.85\n",
            "--------------------------------------------------\n",
            "El mejor modelo es: Regresión Lineal\n",
            "\n",
            "Interpretación:\n",
            "- La Regresión Lineal es más interpretable porque proporciona coeficientes explícitos.\n",
            "- SVR puede capturar relaciones no lineales, pero es menos interpretable y más costoso computacionalmente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar modelo Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,       # Número de árboles\n",
        "    learning_rate=0.1,      # Tasa de aprendizaje\n",
        "    max_depth=3,            # Profundidad máxima de cada árbol\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mse_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "\n",
        "print(\"Resultados del modelo Gradient Boosting:\")\n",
        "print(f\"MSE: {mse_gb:.2f}\")\n",
        "print(f\"RMSE: {rmse_gb:.2f}\")\n",
        "print(f\"R²: {r2_gb:.2f}\")\n",
        "\n",
        "# Importancia de las variables\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': gb_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nImportancia de las variables según Gradient Boosting:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sa87se1S2rC",
        "outputId": "3698077a-2ca2-4851-ab89-746e4eaea49b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados del modelo Gradient Boosting:\n",
            "MSE: 26.57\n",
            "RMSE: 5.15\n",
            "R²: 0.87\n",
            "\n",
            "Importancia de las variables según Gradient Boosting:\n",
            "                  Feature  Importance\n",
            "1      Cantidad_Productos    0.769895\n",
            "0            Distancia_km    0.194560\n",
            "3              Dia_Semana    0.012976\n",
            "5    Tipo_Transporte_Moto    0.007302\n",
            "2             Hora_Pedido    0.006499\n",
            "6             Clima_Nieve    0.002556\n",
            "7           Clima_Soleado    0.002091\n",
            "4  Tipo_Transporte_Camion    0.002007\n",
            "8            Trafico_Leve    0.001151\n",
            "9        Trafico_Moderado    0.000964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (necesario para SVR)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Modelo 1: Regresión Lineal Múltiple\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "rmse_linear = np.sqrt(mse_linear)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "# Modelo 2: Support Vector Regression (SVR)\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "svr_model.fit(X_train_scaled, y_train_scaled)\n",
        "y_pred_svr_scaled = svr_model.predict(X_test_scaled)\n",
        "y_pred_svr = scaler_y.inverse_transform(y_pred_svr_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "# Modelo 3: Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mse_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "\n",
        "# Comparación de modelos\n",
        "print(\"Comparación de modelos:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Regresión Lineal - MSE: {mse_linear:.2f}, RMSE: {rmse_linear:.2f}, R²: {r2_linear:.2f}\")\n",
        "print(f\"SVR - MSE: {mse_svr:.2f}, RMSE: {rmse_svr:.2f}, R²: {r2_svr:.2f}\")\n",
        "print(f\"Gradient Boosting - MSE: {mse_gb:.2f}, RMSE: {rmse_gb:.2f}, R²: {r2_gb:.2f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Determinar el mejor modelo\n",
        "if mse_linear < mse_svr and mse_linear < mse_gb and r2_linear > r2_svr and r2_linear > r2_gb:\n",
        "    print(\"El mejor modelo es: Regresión Lineal\")\n",
        "elif mse_svr < mse_linear and mse_svr < mse_gb and r2_svr > r2_linear and r2_svr > r2_gb:\n",
        "    print(\"El mejor modelo es: SVR\")\n",
        "else:\n",
        "    print(\"El mejor modelo es: Gradient Boosting\")\n",
        "\n",
        "# Resumen de importancia de variables (solo para Gradient Boosting)\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': gb_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nImportancia de las variables según Gradient Boosting:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPddqWXWTT9I",
        "outputId": "4cda4648-123d-4218-ccca-4336c069e918"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de modelos:\n",
            "--------------------------------------------------\n",
            "Regresión Lineal - MSE: 25.98, RMSE: 5.10, R²: 0.87\n",
            "SVR - MSE: 26.88, RMSE: 5.18, R²: 0.86\n",
            "Gradient Boosting - MSE: 26.57, RMSE: 5.15, R²: 0.87\n",
            "--------------------------------------------------\n",
            "El mejor modelo es: Regresión Lineal\n",
            "\n",
            "Importancia de las variables según Gradient Boosting:\n",
            "                  Feature  Importance\n",
            "1      Cantidad_Productos    0.769895\n",
            "0            Distancia_km    0.194560\n",
            "3              Dia_Semana    0.012976\n",
            "5    Tipo_Transporte_Moto    0.007302\n",
            "2             Hora_Pedido    0.006499\n",
            "6             Clima_Nieve    0.002556\n",
            "7           Clima_Soleado    0.002091\n",
            "4  Tipo_Transporte_Camion    0.002007\n",
            "8            Trafico_Leve    0.001151\n",
            "9        Trafico_Moderado    0.000964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica2.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (necesario para SVR)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Modelo 1: Regresión Lineal Múltiple\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "rmse_linear = np.sqrt(mse_linear)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "# Modelo 2: Support Vector Regression (SVR)\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "svr_model.fit(X_train_scaled, y_train_scaled)\n",
        "y_pred_svr_scaled = svr_model.predict(X_test_scaled)\n",
        "y_pred_svr = scaler_y.inverse_transform(y_pred_svr_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "# Modelo 3: Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mse_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "\n",
        "# Comparación de modelos\n",
        "print(\"Comparación de modelos:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Regresión Lineal - MSE: {mse_linear:.2f}, RMSE: {rmse_linear:.2f}, R²: {r2_linear:.2f}\")\n",
        "print(f\"SVR - MSE: {mse_svr:.2f}, RMSE: {rmse_svr:.2f}, R²: {r2_svr:.2f}\")\n",
        "print(f\"Gradient Boosting - MSE: {mse_gb:.2f}, RMSE: {rmse_gb:.2f}, R²: {r2_gb:.2f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Determinar el mejor modelo\n",
        "if mse_linear < mse_svr and mse_linear < mse_gb and r2_linear > r2_svr and r2_linear > r2_gb:\n",
        "    print(\"El mejor modelo es: Regresión Lineal\")\n",
        "elif mse_svr < mse_linear and mse_svr < mse_gb and r2_svr > r2_linear and r2_svr > r2_gb:\n",
        "    print(\"El mejor modelo es: SVR\")\n",
        "else:\n",
        "    print(\"El mejor modelo es: Gradient Boosting\")\n",
        "\n",
        "# Resumen de importancia de variables (solo para Gradient Boosting)\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': gb_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nImportancia de las variables según Gradient Boosting:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LijH3f4kT-pN",
        "outputId": "e2a9e208-8adc-4cd9-f645-9fb9b04911a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de modelos:\n",
            "--------------------------------------------------\n",
            "Regresión Lineal - MSE: 27.93, RMSE: 5.28, R²: 0.86\n",
            "SVR - MSE: 28.84, RMSE: 5.37, R²: 0.85\n",
            "Gradient Boosting - MSE: 28.40, RMSE: 5.33, R²: 0.86\n",
            "--------------------------------------------------\n",
            "El mejor modelo es: Regresión Lineal\n",
            "\n",
            "Importancia de las variables según Gradient Boosting:\n",
            "                Feature  Importance\n",
            "1    Cantidad_Productos    0.777809\n",
            "0          Distancia_km    0.196797\n",
            "3            Dia_Semana    0.013182\n",
            "2           Hora_Pedido    0.006589\n",
            "5         Clima_Soleado    0.003281\n",
            "6          Trafico_Leve    0.001204\n",
            "7      Trafico_Moderado    0.001089\n",
            "4  Tipo_Transporte_Moto    0.000049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica3.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (necesario para SVR)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Modelo 1: Regresión Lineal Múltiple\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "rmse_linear = np.sqrt(mse_linear)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "# Modelo 2: Support Vector Regression (SVR)\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "svr_model.fit(X_train_scaled, y_train_scaled)\n",
        "y_pred_svr_scaled = svr_model.predict(X_test_scaled)\n",
        "y_pred_svr = scaler_y.inverse_transform(y_pred_svr_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "# Modelo 3: Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mse_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "\n",
        "# Comparación de modelos\n",
        "print(\"Comparación de modelos:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Regresión Lineal - MSE: {mse_linear:.2f}, RMSE: {rmse_linear:.2f}, R²: {r2_linear:.2f}\")\n",
        "print(f\"SVR - MSE: {mse_svr:.2f}, RMSE: {rmse_svr:.2f}, R²: {r2_svr:.2f}\")\n",
        "print(f\"Gradient Boosting - MSE: {mse_gb:.2f}, RMSE: {rmse_gb:.2f}, R²: {r2_gb:.2f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Determinar el mejor modelo\n",
        "if mse_linear < mse_svr and mse_linear < mse_gb and r2_linear > r2_svr and r2_linear > r2_gb:\n",
        "    print(\"El mejor modelo es: Regresión Lineal\")\n",
        "elif mse_svr < mse_linear and mse_svr < mse_gb and r2_svr > r2_linear and r2_svr > r2_gb:\n",
        "    print(\"El mejor modelo es: SVR\")\n",
        "else:\n",
        "    print(\"El mejor modelo es: Gradient Boosting\")\n",
        "\n",
        "# Resumen de importancia de variables (solo para Gradient Boosting)\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': gb_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nImportancia de las variables según Gradient Boosting:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0poavgXU1GF",
        "outputId": "22aa4887-fbc3-483d-e082-f9d14f0402eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de modelos:\n",
            "--------------------------------------------------\n",
            "Regresión Lineal - MSE: 30.01, RMSE: 5.48, R²: 0.83\n",
            "SVR - MSE: 29.80, RMSE: 5.46, R²: 0.83\n",
            "Gradient Boosting - MSE: 28.99, RMSE: 5.38, R²: 0.83\n",
            "--------------------------------------------------\n",
            "El mejor modelo es: Gradient Boosting\n",
            "\n",
            "Importancia de las variables según Gradient Boosting:\n",
            "                Feature  Importance\n",
            "1    Cantidad_Productos    0.790385\n",
            "0          Distancia_km    0.184194\n",
            "3            Dia_Semana    0.012803\n",
            "2           Hora_Pedido    0.006890\n",
            "5         Clima_Soleado    0.003485\n",
            "6      Trafico_Moderado    0.002188\n",
            "4  Tipo_Transporte_Moto    0.000054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar modelo XGBoost\n",
        "xgb_model = XGBRegressor(\n",
        "    n_estimators=100,       # Número de árboles\n",
        "    learning_rate=0.1,      # Tasa de aprendizaje\n",
        "    max_depth=3,            # Profundidad máxima de cada árbol\n",
        "    objective='reg:squarederror',  # Función objetivo para regresión\n",
        "    random_state=42\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "rmse_xgb = np.sqrt(mse_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(\"Resultados del modelo XGBoost:\")\n",
        "print(f\"MSE: {mse_xgb:.2f}\")\n",
        "print(f\"RMSE: {rmse_xgb:.2f}\")\n",
        "print(f\"R²: {r2_xgb:.2f}\")\n",
        "\n",
        "# Importancia de las variables\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': xgb_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nImportancia de las variables según XGBoost:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IzsU0pdWjzO",
        "outputId": "deab2931-8ee0-47e0-8c15-a80dcb99a8fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados del modelo XGBoost:\n",
            "MSE: 26.55\n",
            "RMSE: 5.15\n",
            "R²: 0.87\n",
            "\n",
            "Importancia de las variables según XGBoost:\n",
            "                  Feature  Importance\n",
            "1      Cantidad_Productos    0.626693\n",
            "0            Distancia_km    0.180773\n",
            "3              Dia_Semana    0.051328\n",
            "5    Tipo_Transporte_Moto    0.038378\n",
            "6             Clima_Nieve    0.024331\n",
            "4  Tipo_Transporte_Camion    0.022763\n",
            "7           Clima_Soleado    0.015793\n",
            "9        Trafico_Moderado    0.014621\n",
            "2             Hora_Pedido    0.014367\n",
            "8            Trafico_Leve    0.010952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (necesario para SVR)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Modelo 1: Regresión Lineal Múltiple\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "rmse_linear = np.sqrt(mse_linear)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "# Modelo 2: Support Vector Regression (SVR)\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "svr_model.fit(X_train_scaled, y_train_scaled)\n",
        "y_pred_svr_scaled = svr_model.predict(X_test_scaled)\n",
        "y_pred_svr = scaler_y.inverse_transform(y_pred_svr_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "# Modelo 3: Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mse_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "\n",
        "# Modelo 4: XGBoost\n",
        "xgb_model = XGBRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    objective='reg:squarederror',\n",
        "    random_state=42\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "rmse_xgb = np.sqrt(mse_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Comparación de modelos\n",
        "print(\"Comparación de modelos:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Regresión Lineal - MSE: {mse_linear:.2f}, RMSE: {rmse_linear:.2f}, R²: {r2_linear:.2f}\")\n",
        "print(f\"SVR - MSE: {mse_svr:.2f}, RMSE: {rmse_svr:.2f}, R²: {r2_svr:.2f}\")\n",
        "print(f\"Gradient Boosting - MSE: {mse_gb:.2f}, RMSE: {rmse_gb:.2f}, R²: {r2_gb:.2f}\")\n",
        "print(f\"XGBoost - MSE: {mse_xgb:.2f}, RMSE: {rmse_xgb:.2f}, R²: {r2_xgb:.2f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Determinar el mejor modelo\n",
        "if mse_linear < mse_svr and mse_linear < mse_gb and mse_linear < mse_xgb and r2_linear > r2_svr and r2_linear > r2_gb and r2_linear > r2_xgb:\n",
        "    print(\"El mejor modelo es: Regresión Lineal\")\n",
        "elif mse_svr < mse_linear and mse_svr < mse_gb and mse_svr < mse_xgb and r2_svr > r2_linear and r2_svr > r2_gb and r2_svr > r2_xgb:\n",
        "    print(\"El mejor modelo es: SVR\")\n",
        "elif mse_gb < mse_linear and mse_gb < mse_svr and mse_gb < mse_xgb and r2_gb > r2_linear and r2_gb > r2_svr and r2_gb > r2_xgb:\n",
        "    print(\"El mejor modelo es: Gradient Boosting\")\n",
        "else:\n",
        "    print(\"El mejor modelo es: XGBoost\")\n",
        "\n",
        "# Resumen de importancia de variables (solo para Gradient Boosting y XGBoost)\n",
        "importance_gb_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance_GB': gb_model.feature_importances_\n",
        "}).sort_values(by='Importance_GB', ascending=False)\n",
        "\n",
        "importance_xgb_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance_XGB': xgb_model.feature_importances_\n",
        "}).sort_values(by='Importance_XGB', ascending=False)\n",
        "\n",
        "print(\"\\nImportancia de las variables según Gradient Boosting:\")\n",
        "print(importance_gb_df)\n",
        "\n",
        "print(\"\\nImportancia de las variables según XGBoost:\")\n",
        "print(importance_xgb_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU05VxQbW4Xy",
        "outputId": "6dbc3788-b697-40c3-fd9d-3827623e7b5a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de modelos:\n",
            "--------------------------------------------------\n",
            "Regresión Lineal - MSE: 25.98, RMSE: 5.10, R²: 0.87\n",
            "SVR - MSE: 26.88, RMSE: 5.18, R²: 0.86\n",
            "Gradient Boosting - MSE: 26.57, RMSE: 5.15, R²: 0.87\n",
            "XGBoost - MSE: 26.55, RMSE: 5.15, R²: 0.87\n",
            "--------------------------------------------------\n",
            "El mejor modelo es: Regresión Lineal\n",
            "\n",
            "Importancia de las variables según Gradient Boosting:\n",
            "                  Feature  Importance_GB\n",
            "1      Cantidad_Productos       0.769895\n",
            "0            Distancia_km       0.194560\n",
            "3              Dia_Semana       0.012976\n",
            "5    Tipo_Transporte_Moto       0.007302\n",
            "2             Hora_Pedido       0.006499\n",
            "6             Clima_Nieve       0.002556\n",
            "7           Clima_Soleado       0.002091\n",
            "4  Tipo_Transporte_Camion       0.002007\n",
            "8            Trafico_Leve       0.001151\n",
            "9        Trafico_Moderado       0.000964\n",
            "\n",
            "Importancia de las variables según XGBoost:\n",
            "                  Feature  Importance_XGB\n",
            "1      Cantidad_Productos        0.626693\n",
            "0            Distancia_km        0.180773\n",
            "3              Dia_Semana        0.051328\n",
            "5    Tipo_Transporte_Moto        0.038378\n",
            "6             Clima_Nieve        0.024331\n",
            "4  Tipo_Transporte_Camion        0.022763\n",
            "7           Clima_Soleado        0.015793\n",
            "9        Trafico_Moderado        0.014621\n",
            "2             Hora_Pedido        0.014367\n",
            "8            Trafico_Leve        0.010952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica3.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (necesario para SVR y KNN)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Función para evaluar modelos\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, scaled=False):\n",
        "    if scaled:\n",
        "        model.fit(X_train_scaled, y_train_scaled)\n",
        "        y_pred_scaled = model.predict(X_test_scaled)\n",
        "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return mse, rmse, r2\n",
        "\n",
        "# Entrenar y evaluar modelos\n",
        "models = {\n",
        "    \"Regresión Lineal\": LinearRegression(),\n",
        "    \"SVR\": SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
        "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, objective='reg:squarederror', random_state=42),\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    print(f\"Entrenando {name}...\")\n",
        "    scaled = name in [\"SVR\", \"KNN\"]  # Escalar solo para SVR y KNN\n",
        "    mse, rmse, r2 = evaluate_model(model, X_train, X_test, y_train, y_test, scaled=scaled)\n",
        "    results.append((name, mse, rmse, r2))\n",
        "    print(f\"{name} - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}\")\n",
        "\n",
        "# Modelo de Red Neuronal (Deep Learning)\n",
        "print(\"Entrenando Red Neuronal...\")\n",
        "nn_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Capa de salida para regresión\n",
        "])\n",
        "nn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "nn_model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "y_pred_nn_scaled = nn_model.predict(X_test_scaled).ravel()\n",
        "y_pred_nn = scaler_y.inverse_transform(y_pred_nn_scaled.reshape(-1, 1)).ravel()\n",
        "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
        "rmse_nn = np.sqrt(mse_nn)\n",
        "r2_nn = r2_score(y_test, y_pred_nn)\n",
        "results.append((\"Red Neuronal\", mse_nn, rmse_nn, r2_nn))\n",
        "print(f\"Red Neuronal - MSE: {mse_nn:.2f}, RMSE: {rmse_nn:.2f}, R²: {r2_nn:.2f}\")\n",
        "\n",
        "# Comparación de modelos\n",
        "print(\"\\nComparación de modelos:\")\n",
        "print(\"-\" * 50)\n",
        "for name, mse, rmse, r2 in results:\n",
        "    print(f\"{name} - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Determinar el mejor modelo\n",
        "best_model = min(results, key=lambda x: x[1])  # Menor MSE\n",
        "print(f\"\\nEl mejor modelo es: {best_model[0]} con MSE: {best_model[1]:.2f}, RMSE: {best_model[2]:.2f}, R²: {best_model[3]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tciHcBv0XyN8",
        "outputId": "55e4d759-664d-4ffb-a088-ba46a0b91e95"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando Regresión Lineal...\n",
            "Regresión Lineal - MSE: 30.01, RMSE: 5.48, R²: 0.83\n",
            "Entrenando SVR...\n",
            "SVR - MSE: 29.80, RMSE: 5.46, R²: 0.83\n",
            "Entrenando KNN...\n",
            "KNN - MSE: 35.75, RMSE: 5.98, R²: 0.79\n",
            "Entrenando Decision Tree...\n",
            "Decision Tree - MSE: 60.04, RMSE: 7.75, R²: 0.65\n",
            "Entrenando Random Forest...\n",
            "Random Forest - MSE: 33.04, RMSE: 5.75, R²: 0.81\n",
            "Entrenando Gradient Boosting...\n",
            "Gradient Boosting - MSE: 28.99, RMSE: 5.38, R²: 0.83\n",
            "Entrenando XGBoost...\n",
            "XGBoost - MSE: 28.94, RMSE: 5.38, R²: 0.83\n",
            "Entrenando Red Neuronal...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
            "Red Neuronal - MSE: 29.33, RMSE: 5.42, R²: 0.83\n",
            "\n",
            "Comparación de modelos:\n",
            "--------------------------------------------------\n",
            "Regresión Lineal - MSE: 30.01, RMSE: 5.48, R²: 0.83\n",
            "SVR - MSE: 29.80, RMSE: 5.46, R²: 0.83\n",
            "KNN - MSE: 35.75, RMSE: 5.98, R²: 0.79\n",
            "Decision Tree - MSE: 60.04, RMSE: 7.75, R²: 0.65\n",
            "Random Forest - MSE: 33.04, RMSE: 5.75, R²: 0.81\n",
            "Gradient Boosting - MSE: 28.99, RMSE: 5.38, R²: 0.83\n",
            "XGBoost - MSE: 28.94, RMSE: 5.38, R²: 0.83\n",
            "Red Neuronal - MSE: 29.33, RMSE: 5.42, R²: 0.83\n",
            "--------------------------------------------------\n",
            "\n",
            "El mejor modelo es: XGBoost con MSE: 28.94, RMSE: 5.38, R²: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar e instalar bibliotecas necesarias\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_and_import(package):\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        print(f\"Instalando {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "    finally:\n",
        "        globals()[package] = __import__(package)\n",
        "\n",
        "# Lista de bibliotecas necesarias\n",
        "required_packages = [\"xgboost\", \"lightgbm\", \"catboost\", \"tensorflow\"]\n",
        "\n",
        "for package in required_packages:\n",
        "    install_and_import(package)\n",
        "\n",
        "# Continuar con el código principal\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Resto del código..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfXYeYUSZ_dv",
        "outputId": "45d6eae4-2fdf-4adf-dbd3-d30f382f1eae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando catboost...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Cargar los datos\n",
        "url = 'https://github.com/santiagoNajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Convertir variables categóricas a numéricas con one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Separar features y target\n",
        "X = data.drop('Tiempo_Entrega', axis=1)\n",
        "y = data['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (necesario para algunos modelos)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Función para evaluar modelos\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, scaled=False):\n",
        "    if scaled:\n",
        "        model.fit(X_train_scaled, y_train_scaled)\n",
        "        y_pred_scaled = model.predict(X_test_scaled)\n",
        "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return mse, rmse, r2\n",
        "\n",
        "# Entrenar y evaluar modelos\n",
        "models = {\n",
        "    \"Regresión Lineal\": LinearRegression(),\n",
        "    \"SVR\": SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
        "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
        "    \"Árbol de Decisión\": DecisionTreeRegressor(random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, objective='reg:squarederror', random_state=42),\n",
        "    \"LightGBM\": LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
        "    \"CatBoost\": CatBoostRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, verbose=0, random_state=42),\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    print(f\"Entrenando {name}...\")\n",
        "    scaled = name in [\"SVR\", \"KNN\"]  # Escalar solo para SVR y KNN\n",
        "    mse, rmse, r2 = evaluate_model(model, X_train, X_test, y_train, y_test, scaled=scaled)\n",
        "    results.append((name, mse, rmse, r2))\n",
        "    print(f\"{name} - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}\")\n",
        "\n",
        "# Modelo de Red Neuronal (Deep Learning)\n",
        "print(\"Entrenando Red Neuronal...\")\n",
        "nn_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Capa de salida para regresión\n",
        "])\n",
        "nn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "nn_model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "y_pred_nn_scaled = nn_model.predict(X_test_scaled).ravel()\n",
        "y_pred_nn = scaler_y.inverse_transform(y_pred_nn_scaled.reshape(-1, 1)).ravel()\n",
        "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
        "rmse_nn = np.sqrt(mse_nn)\n",
        "r2_nn = r2_score(y_test, y_pred_nn)\n",
        "results.append((\"Red Neuronal\", mse_nn, rmse_nn, r2_nn))\n",
        "print(f\"Red Neuronal - MSE: {mse_nn:.2f}, RMSE: {rmse_nn:.2f}, R²: {r2_nn:.2f}\")\n",
        "\n",
        "# Comparación de modelos\n",
        "print(\"\\nComparación de modelos:\")\n",
        "print(\"-\" * 50)\n",
        "for name, mse, rmse, r2 in results:\n",
        "    print(f\"{name} - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Determinar el mejor modelo\n",
        "best_model = min(results, key=lambda x: x[1])  # Menor MSE\n",
        "print(f\"\\nEl mejor modelo es: {best_model[0]} con MSE: {best_model[1]:.2f}, RMSE: {best_model[2]:.2f}, R²: {best_model[3]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "Wu-3GqJ2ZM2K",
        "outputId": "4bdc949a-6233-427f-f66c-d715693fa4f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'catboost'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ed8af1e60c57>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Cargar los datos originales para entrenamiento\n",
        "url_train = 'https://github.com/santiagonajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica3.csv'\n",
        "data_train = pd.read_csv(url_train)\n",
        "\n",
        "# Cargar los datos nuevos para predicción\n",
        "url_predict = 'https://github.com/santiagonajera/Regresiones-Aplicaciones-en-Logistica/raw/refs/heads/main/transporte_datos_logistica_por_pred.csv'\n",
        "data_predict = pd.read_csv(url_predict)\n",
        "\n",
        "# Preprocesamiento de datos (entrenamiento)\n",
        "data_train = pd.get_dummies(data_train, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "X_train_full = data_train.drop('Tiempo_Entrega', axis=1)\n",
        "y_train_full = data_train['Tiempo_Entrega']\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características (necesario para algunos modelos)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
        "y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1)).ravel()\n",
        "\n",
        "# Función para evaluar modelos\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, scaled=False):\n",
        "    if scaled:\n",
        "        model.fit(X_train_scaled, y_train_scaled)\n",
        "        y_pred_scaled = model.predict(X_test_scaled)\n",
        "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return mse, rmse, r2\n",
        "\n",
        "# Entrenar y evaluar modelos\n",
        "models = {\n",
        "    \"Regresión Lineal\": LinearRegression(),\n",
        "    \"SVR\": SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
        "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
        "    \"Árbol de Decisión\": DecisionTreeRegressor(random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, objective='reg:squarederror', random_state=42),\n",
        "    \"LightGBM\": LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
        "    \"CatBoost\": CatBoostRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, verbose=0, random_state=42),\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    print(f\"Entrenando {name}...\")\n",
        "    scaled = name in [\"SVR\", \"KNN\"]  # Escalar solo para SVR y KNN\n",
        "    mse, rmse, r2 = evaluate_model(model, X_train, X_test, y_train, y_test, scaled=scaled)\n",
        "    results.append((name, mse, rmse, r2))\n",
        "    print(f\"{name} - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}\")\n",
        "\n",
        "# Modelo de Red Neuronal (Deep Learning)\n",
        "print(\"Entrenando Red Neuronal...\")\n",
        "nn_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Capa de salida para regresión\n",
        "])\n",
        "nn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "nn_model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "y_pred_nn_scaled = nn_model.predict(X_test_scaled).ravel()\n",
        "y_pred_nn = scaler_y.inverse_transform(y_pred_nn_scaled.reshape(-1, 1)).ravel()\n",
        "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
        "rmse_nn = np.sqrt(mse_nn)\n",
        "r2_nn = r2_score(y_test, y_pred_nn)\n",
        "results.append((\"Red Neuronal\", mse_nn, rmse_nn, r2_nn))\n",
        "print(f\"Red Neuronal - MSE: {mse_nn:.2f}, RMSE: {rmse_nn:.2f}, R²: {r2_nn:.2f}\")\n",
        "\n",
        "# Comparación de modelos\n",
        "print(\"\\nComparación de modelos:\")\n",
        "print(\"-\" * 50)\n",
        "for name, mse, rmse, r2 in results:\n",
        "    print(f\"{name} - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Determinar el mejor modelo\n",
        "best_model_info = min(results, key=lambda x: x[1])  # Menor MSE\n",
        "best_model_name = best_model_info[0]\n",
        "best_model_mse = best_model_info[1]\n",
        "best_model_rmse = best_model_info[2]\n",
        "best_model_r2 = best_model_info[3]\n",
        "\n",
        "print(f\"\\nEl mejor modelo es: {best_model_name} con MSE: {best_model_mse:.2f}, RMSE: {best_model_rmse:.2f}, R²: {best_model_r2:.2f}\")\n",
        "\n",
        "# Aplicar el mejor modelo a los datos nuevos\n",
        "# Preprocesamiento de datos nuevos\n",
        "data_predict = pd.get_dummies(data_predict, columns=['Tipo_Transporte', 'Clima', 'Trafico'], drop_first=True)\n",
        "\n",
        "# Asegurar que las columnas coincidan con las del conjunto de entrenamiento\n",
        "missing_cols = set(X_train_full.columns) - set(data_predict.columns)\n",
        "for col in missing_cols:\n",
        "    data_predict[col] = 0  # Agregar columnas faltantes con valor 0\n",
        "data_predict = data_predict[X_train_full.columns]  # Reordenar columnas\n",
        "\n",
        "# Escalar los datos nuevos si es necesario\n",
        "scaled_data_predict = scaler_X.transform(data_predict)\n",
        "\n",
        "# Seleccionar y aplicar el mejor modelo\n",
        "if best_model_name == \"Red Neuronal\":\n",
        "    predictions = nn_model.predict(scaled_data_predict).ravel()\n",
        "    predictions = scaler_y.inverse_transform(predictions.reshape(-1, 1)).ravel()\n",
        "else:\n",
        "    best_model = [model for name, model in models.items() if name == best_model_name][0]\n",
        "    if best_model_name in [\"SVR\", \"KNN\"]:\n",
        "        predictions = best_model.predict(scaled_data_predict)\n",
        "        predictions = scaler_y.inverse_transform(predictions.reshape(-1, 1)).ravel()\n",
        "    else:\n",
        "        predictions = best_model.predict(data_predict)\n",
        "\n",
        "# Mostrar las predicciones\n",
        "data_predict['Tiempo_Entrega_Predicho'] = predictions\n",
        "print(\"\\nPredicciones de Tiempo_Entrega para los datos nuevos:\")\n",
        "print(data_predict[['Tiempo_Entrega_Predicho']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxa6Mnc0bYpv",
        "outputId": "6178d58e-15c3-40f4-d277-2d52b2ad7754"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando Regresión Lineal...\n",
            "Regresión Lineal - MSE: 30.01, RMSE: 5.48, R²: 0.83\n",
            "Entrenando SVR...\n",
            "SVR - MSE: 29.80, RMSE: 5.46, R²: 0.83\n",
            "Entrenando KNN...\n",
            "KNN - MSE: 35.75, RMSE: 5.98, R²: 0.79\n",
            "Entrenando Árbol de Decisión...\n",
            "Árbol de Decisión - MSE: 60.04, RMSE: 7.75, R²: 0.65\n",
            "Entrenando Random Forest...\n",
            "Random Forest - MSE: 33.04, RMSE: 5.75, R²: 0.81\n",
            "Entrenando Gradient Boosting...\n",
            "Gradient Boosting - MSE: 28.99, RMSE: 5.38, R²: 0.83\n",
            "Entrenando AdaBoost...\n",
            "AdaBoost - MSE: 35.25, RMSE: 5.94, R²: 0.79\n",
            "Entrenando XGBoost...\n",
            "XGBoost - MSE: 28.94, RMSE: 5.38, R²: 0.83\n",
            "Entrenando LightGBM...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 447\n",
            "[LightGBM] [Info] Number of data points in the train set: 13200, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 60.595841\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM - MSE: 28.93, RMSE: 5.38, R²: 0.83\n",
            "Entrenando CatBoost...\n",
            "CatBoost - MSE: 29.02, RMSE: 5.39, R²: 0.83\n",
            "Entrenando Red Neuronal...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Red Neuronal - MSE: 29.61, RMSE: 5.44, R²: 0.83\n",
            "\n",
            "Comparación de modelos:\n",
            "--------------------------------------------------\n",
            "Regresión Lineal - MSE: 30.01, RMSE: 5.48, R²: 0.83\n",
            "SVR - MSE: 29.80, RMSE: 5.46, R²: 0.83\n",
            "KNN - MSE: 35.75, RMSE: 5.98, R²: 0.79\n",
            "Árbol de Decisión - MSE: 60.04, RMSE: 7.75, R²: 0.65\n",
            "Random Forest - MSE: 33.04, RMSE: 5.75, R²: 0.81\n",
            "Gradient Boosting - MSE: 28.99, RMSE: 5.38, R²: 0.83\n",
            "AdaBoost - MSE: 35.25, RMSE: 5.94, R²: 0.79\n",
            "XGBoost - MSE: 28.94, RMSE: 5.38, R²: 0.83\n",
            "LightGBM - MSE: 28.93, RMSE: 5.38, R²: 0.83\n",
            "CatBoost - MSE: 29.02, RMSE: 5.39, R²: 0.83\n",
            "Red Neuronal - MSE: 29.61, RMSE: 5.44, R²: 0.83\n",
            "--------------------------------------------------\n",
            "\n",
            "El mejor modelo es: LightGBM con MSE: 28.93, RMSE: 5.38, R²: 0.83\n",
            "\n",
            "Predicciones de Tiempo_Entrega para los datos nuevos:\n",
            "   Tiempo_Entrega_Predicho\n",
            "0                48.592036\n",
            "1                65.620493\n",
            "2                70.384636\n",
            "3                48.127665\n",
            "4                54.681800\n",
            "5                66.263350\n",
            "6                51.275440\n",
            "7                79.631298\n",
            "8                52.094122\n",
            "9                57.658104\n"
          ]
        }
      ]
    }
  ]
}